- #TroubleShooting #Springboot #aws
- ### I. 문제 상황
	- 웹훅 API와 REST API를 통해 쇼핑 채널별 통합 주문/재고 관리 서비스를 개발하면서, 사이즈가 큰 JSON을 파싱해야하는 상황이 발생했다.
		- JSON 파싱 결과를 저장하는 과정에서 매번 값의 유효성 검증을 위한 다수의 단순 조회성 DB I/O가 발생하고고, 이로 인한 효율 감소 우려
		  logseq.order-list-type:: number
		- 주문이 발생하면 사용자에게 알림을 전송하도록 설계하였는데, API 호출량이 증가하면 아웃바운드 트래픽 증가로 서버비가 급증할 가능성이 있지 않을까?
		  logseq.order-list-type:: number
	- 실무에서는 서버를 스케일업/아웃하더라도 사용자 편의를 위해 서버 성능을 향상시키는 것이 맞겠지만, 당시 실사용자에게 서비스하는 것이 아니라 테스트 배포 수준이었기 때문에 (+ 서버 자원을 학교를 통해 공급받고 있었기 때문에 서버 스케일업이 불가능했다)
	- 캡스톤 완성작 발표회를 앞두고 있었기 때문에, 테스트와 데모 시연을 위해서 클라이언트 API의 응답 속도는 최대한 빨라야 했다. 하지만, 자바의 스레드 기능을 활용해 10개의 스레드에서 동시에 순차적으로 응답을 발생시키고 결과를 확인한 결과, JSON 파싱 프로세스가 클라이언트 API 응답에도 영향을 미쳐 Tomcat의 최대 연결 풀에 도달하지 않았음에도 클라이언트 응답이 최대 1200ms까지 증가하는 것을 관측했다.
	-
	- 따라서, 기존 서버와 동일한 스펙으로 클라이언트 API 응답 지연을 최소화하기 위해 서버 병목 분산이 필요했다.
-
- ### II. 배경 지식
	- [[이벤트 중심 아키텍처]]
-
- ### III. 문제 해결 과정
	- [[AWS SQS 기반 Message Queue 도입하기]]
	- 메시지 큐를 도입함과 동시에, JSON 파싱 및 저장 프로세스의 워커 스레드 수를 엄격하게 제한했다.
		- 해당 프로젝트 시연은 많은 사람들이 동시에 주문을 발생시키지 않을 것으로 생각해 웹훅 (시연 당시 활용한 Shopify 쇼핑몰은 주문 발생 시점에 웹훅으로 주문 정보를 제공함) POST 요청이 동시에 3개 이상 발생하지 않을 것으로 생각하여 워커 스레드를 한 개로 제한했다.
-
- ### IV. 결론
	- 1200ms까지 증가했던 클라이언트 API 응답 속도가 동일한 방법으로 측정했을 때 평균 300ms에서 유지되었다.
	-
	- 단, 메시지 큐의 소비자 수를 극단적으로 제한하였기 때문에, 주문이 짧은 기간 동안 많이 발생한다면 사용자가 주문이 업데이트된 DB 확인하는 속도가 늦어질 우려가 있다.
		- 이 문제는 [[정규화된 DB에서 조회 연산 효율화하기 - CQRS 패턴]]과 같은 방법으로 일부 해소할 수 있지 않을까?
	- 강도테스트를 수동으로 코드를 작성하는 방식으로 진행했는데, 개발계에 배포할 때마다 자동으로 테스트를 진행하도록 하거나, 최소한 코드를 프로젝트와 함께 관리하는 방법으로 개선하는 것이 협업에 도움이 될 것 같다.
		- LATER [[테스트 코드 작성 요령 및 TDD 이해하기]]
		  :LOGBOOK:
		  CLOCK: [2025-07-16 Wed 03:31:50]--[2025-07-16 Wed 03:31:50] =>  00:00:00
		  CLOCK: [2025-07-16 Wed 03:31:54]--[2025-07-16 Wed 03:31:55] =>  00:00:01
		  CLOCK: [2025-07-16 Wed 03:31:56]--[2025-07-16 Wed 03:31:57] =>  00:00:01
		  CLOCK: [2025-07-16 Wed 03:31:58]--[2025-07-16 Wed 03:31:59] =>  00:00:01
		  CLOCK: [2025-07-16 Wed 03:32:06]--[2025-07-16 Wed 03:32:06] =>  00:00:00
		  :END:
-
- ### 수정 기록
	- [[Jul 23rd, 2025]] 최초 발행